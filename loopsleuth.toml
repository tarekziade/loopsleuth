# LoopSleuth Performance Checks Configuration
#
# This file defines the performance checks that LoopSleuth runs on Python code.
# It uses shared prompt templates (basis) to keep all checkers consistent.
#
# IMPORTANT (expected by runner):
# - The LLM must return a COMPLETE updated function (not a diff).
# - LoopSleuth will compute the diff itself.
# - The runner should support template expansion:
#     - If a prompt is "{template:<name>}", substitute it with templates.<name>
#     - Then interpolate placeholders:
#         {name}, {keyword}, {function_source}, {solution}, {detection_rules}, {fix_recipes}

[settings]
# Default CLI options (all are optional and can be overridden by CLI flags)
# model = "./models/qwen2.5-coder-3b-instruct-q4_k_m.gguf"  # Path to GGUF model
# threads = 4                                                 # Number of inference threads
# max_tokens = 1024                                           # Maximum tokens to generate (increased for detailed diffs)
# context_size = 4096                                         # Context window size
# skip_large = 0                                              # Skip functions larger than N lines
# cache_dir = ".loopsleuth_cache"                             # Cache directory path

# =========================
# Dedupe rules
# =========================

[[dedupe]]
# Prefer linear-in-loop and drop quadratic when both fire for the same function
prefer = "linear-in-loop"
drop = ["quadratic"]


# =========================
# Shared prompt templates
# =========================
[templates]

# Detection template: always returns a 4-line verdict for machine parsing.
detection_basis = """<|im_start|>system
You are a strict performance check. You MUST follow the output format exactly.

Rules:
- Output must be exactly 4 lines: VERDICT, CONFIDENCE, DETAIL, END.
- VERDICT must be either: "VERDICT: OK" OR "VERDICT: {keyword}" (use the check keyword EXACTLY).
- CONFIDENCE must be a float 0.00-1.00.
- DETAIL must cite concrete code tokens/operations from the function (e.g., "list.index() in loop", "torch.tril inside layer loop").
- If uncertain, output VERDICT: OK with lower confidence.
- Do NOT include any other text.

{detection_rules}

<|im_end|>
<|im_start|>user
Check "{name}" with keyword "{keyword}".

Function:
```python
{function_source}
```

<|im_end|>
<|im_start|>assistant
"""

# Solution template: ALWAYS returns the complete updated function (NOT a diff).
solution_basis = """<|im_start|>system
You are an expert performance engineer. Output the COMPLETE updated function (not a diff).

Hard constraints:
- Output MUST be exactly one ```python fenced block and nothing else.
- The block must contain the FULL function definition (complete, runnable).
- Keep the EXACT function signature (the def line, parameters, defaults, type hints) unchanged.
- Preserve behavior unless the change is strictly required to fix the performance issue.
- Do NOT add new dependencies.
- Do NOT add error handling unless the original had it.
- Add at most one short comment explaining the optimization.

Fix guidance for this check:
{fix_recipes}

<|im_end|>
<|im_start|>user
Issue keyword: {keyword}

Function to optimize:
```python
{function_source}
```

Output the COMPLETE updated version of this function.
<|im_end|>
<|im_start|>assistant
```python
"""

# Verifier template: validates ORIGINAL vs NEW FUNCTION (full function), not a diff.
verifier_basis = """<|im_start|>system
You are a strict patch verifier.

Input:
- ORIGINAL FUNCTION
- PROPOSED NEW FUNCTION (full function)

Output exactly:
VERDICT: VALID | INVALID
REASON: <one short reason, concrete>
END

INVALID if:
- Proposed output is missing a ```python fenced block with a full function
- Function signature (def line) changed
- Introduces obvious syntax errors
- References undefined variables (obvious)
- Does not appear to address the stated issue keyword at all (best-effort)
- Changes meaning in risky ways unrelated to the performance fix

Do not add anything else.
<|im_end|>
<|im_start|>user
Issue keyword: {keyword}

Original function:
```python
{function_source}
```

Proposed new function:
{solution}

Is this valid? Output VERDICT:, REASON:, END.
<|im_end|>
<|im_start|>assistant
"""


# =========================
# Checks
# =========================

[[check]]
key = "quadratic"
name = "Quadratic Complexity"
description = "Detects O(n²) or worse time complexity patterns (nested loops, etc.)"
category = "performance"
keyword = "QUADRATIC"

detection_rules = """Look for these quadratic patterns:
1. Nested loops iterating over the same or related data structures
2. Linear operations inside loops: list.index(), x in list, list.remove()
3. Operations that are O(n) being called n times

Define symbols when relevant:
- N = number of items/tokens processed (dominant scaling dimension)

Only label QUADRATIC if runtime is Ω(N^2) or worse with respect to N.

IMPORTANT: Nested loops alone are NOT quadratic unless they iterate over related data.
- QUADRATIC: for i in items: for j in items: (same data)
- QUADRATIC: for item in items: idx = list.index(item) (O(n) in O(n) loop)
- NOT QUADRATIC: for i in batch: for j in features: (independent dimensions)
"""

fix_recipes = """Pick the smallest safe transformation that removes Ω(N^2):

A) If you see `list.index(x)` in a loop:
- Precompute a lookup dict BEFORE the loop:
  `value_to_index = {v: i for i, v in enumerate(the_list)}`
- Replace `.index(x)` with `value_to_index[x]`

B) If you see `x in some_list` inside a loop (membership test):
- Precompute `some_set = set(some_list)` once (outside the loop)
- Replace with `x in some_set`

C) If you see nested loops over the same `items` doing comparisons/joins:
- Consider building a dict/set keyed by the join key and doing O(1) lookups.
- Preserve ordering semantics unless the original treats data as unordered.
- Avoid refactors that change tie-breaking or output order.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = ["for ", "while "]



[[check]]
key = "linear-in-loop"
name = "Linear Operations in Loops"
description = "Detects hidden O(n) operations in loops (list.remove(), x in list, etc.)"
category = "performance"
keyword = "LINEAR_IN_LOOP"

detection_rules = """Look for these patterns in loops:
- `x in list` membership tests (O(n) per check)
- `list.remove(x)` operations (O(n) per removal)
- `list.index(x)` lookups (O(n) per lookup)
- `list.pop(0)` from front of list (O(n) per pop)
- String concatenation with += in loops (often O(n^2) overall)

Only flag if the exact operation appears in the loop body. Do NOT infer.
Do NOT flag tensor slicing/assignment or plain indexing (e.g., `tensor[i, j] = ...`).
Do NOT flag `list.index()` unless it is called directly in the loop body.
If no such operations are present, output VERDICT: OK.
"""

fix_recipes = """Use the smallest safe change:

A) Membership test in a loop:
- If `x in some_list` occurs inside a loop and `some_list` is not changing:
  - Precompute `some_set = set(some_list)` before the loop
  - Replace with `x in some_set`

B) `list.index(x)` in a loop:
- Precompute `value_to_index = {v: i for i, v in enumerate(the_list)}`
- Replace `.index(x)` with `value_to_index[x]`

C) `list.pop(0)` in a loop:
- If behavior is queue-like, use `collections.deque` and `popleft()` (hoist conversion once)

D) `list.remove(x)` in a loop:
- Prefer building a new list (filter) if semantics match.
- If semantics are tricky (removing while iterating), keep behavior identical and add only a short comment if no safe change exists.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"


[[check]]
key = "expensive-sort-key"
name = "Expensive Sort Key"
description = "Detects O(n) key functions in sort/sorted operations"
category = "performance"
keyword = "EXPENSIVE_SORT_KEY"

detection_rules = """Look for sort/sorted with key functions that are O(n):
- `key=lambda x: list.index(x)` - O(n) lookup per element
- `key=lambda x: x in other_list` - O(n) membership test per element
- expensive regex (e.g., `re.match`) per element

If there is no `sort(...)` or `sorted(...)` call, output VERDICT: OK.
"""

fix_recipes = """A) key uses `list.index(x)`:
- Precompute `value_to_index = {v: i for i, v in enumerate(the_list)}`
- Replace key with `key=lambda x: value_to_index[x]` (or `.get(x, default)` if original allowed missing)

B) key uses membership `x in other_list`:
- Precompute `other_set = set(other_list)` once
- Replace with `key=lambda x: x in other_set`

C) key uses regex repeatedly:
- Precompile the regex outside: `pattern = re.compile(...)`
- Use `pattern.match` in the key

Be careful:
- Preserve stable ordering and tie-breaking behavior of the original sort.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = ["sorted(", ".sort("]




[[check]]
key = "unbounded-alloc"
name = "Unbounded Allocations"
description = "Detects growing allocations in loops (string concat, repeated cat)"
category = "performance"
keyword = "UNBOUNDED_ALLOC"

detection_rules = """ONLY flag these TRUE unbounded allocation patterns:
- String concatenation with += in loops (creates new string each iteration)
- Repeated list/array concatenation (e.g., `result = result + [item]`)
- `torch.cat()` or `np.concatenate()` repeatedly called in loops

DO NOT flag (they are SAFE):
- Bounded loops like `for i in range(n)` where n is fixed
- Appending to a list (e.g., `list.append(x)`)
- Counter increments (e.g., `count += 1`)
"""

fix_recipes = """A) String concatenation in a loop:
- Replace `s += piece` with:
  - `parts.append(piece)` inside the loop
  - `s = ''.join(parts)` after the loop

B) Repeated list concatenation:
- Replace `result = result + [x]` with `result.append(x)` (or `extend`)

C) Repeated torch/np concatenate in a loop:
- Collect tensors/arrays into a list during the loop
- Concatenate once after the loop

Preserve behavior:
- Keep exact output formatting and ordering.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"


[[check]]
key = "conversion-churn"
name = "Conversion Churn"
description = "Detects repeated CPU/GPU or tensor/array conversions in loops"
category = "ml-specific"
keyword = "CONVERSION_CHURN"

detection_rules = """Look for these patterns in loops:
- Repeated `.cpu()` or `.cuda()` or `.to(device)` calls
- Repeated `.numpy()` conversions from tensors
- Repeated `torch.tensor()` or `torch.from_numpy()` conversions
- Back-and-forth between CPU and GPU

Only flag if conversions are repeated INSIDE a loop and the conversion target is invariant.
Require at least one of these tokens to appear INSIDE the loop body:
`.cpu(`, `.cuda(`, `.to(`, `.numpy(`, `torch.tensor(`, `torch.from_numpy(`.
Do NOT flag single conversions or functions with no explicit Python loop.
"""

fix_recipes = """Hoist invariant conversions:

A) `.to(device)`, `.cpu()`, `.cuda()` inside a loop:
- If the tensor/array being converted does not change across iterations, move conversion outside loop.
- If each iteration produces a tensor, consider converting once on the final batch output (if semantics match).

B) `.numpy()` in a loop:
- Prefer collecting tensors and converting once (or converting the batch) if safe.

C) `torch.tensor(...)` in a loop:
- If converting from a Python list/np array, preconvert once outside when invariant, or batch the conversion.

Avoid:
- Changing dtype/device semantics.
- Adding synchronization or extra copies.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = [".cpu(", ".cuda(", ".to(", ".numpy(", "torch.tensor(", "torch.from_numpy("]
require_regex_any = ['\btorch\.tensor\s*\(', '\btorch\.from_numpy\s*\(']




[[check]]
key = "python-loop-over-token-dimension"
name = "Python Loop Over Token Dimension"
description = "Detects Python loops iterating over token/sequence dimensions in ML models"
category = "ml-specific"
keyword = "ML_LOOP_OVER_TOKENS"

detection_rules = """Only flag if:
- A Python loop iterates over a tensor/array dimension (len(tensor), tensor.shape[0], range(seq_len))
- The loop body indexes the tensor by the loop variable (e.g., tensor[i], tensor[:, i])
- This is likely a vectorization opportunity over the token/sequence dimension

DO NOT flag:
- Loops over layers/experts (architectural)
- Loops for batching multiple sequences
- Single-use initialization code
- Loops over Python lists of images/batches (not token dimension)
"""

fix_recipes = """Prefer minimal safe improvement:

A) If a clear vectorized equivalent exists and preserves semantics:
- Replace per-token Python loop with a tensor operation over the whole dimension.

B) If vectorization is risky without broader context:
- Hoist invariant computations out of the loop (e.g., constants, masks, device conversions)
- Add one short comment indicating potential vectorization, but keep behavior identical.

Do NOT:
- Change shapes, broadcasting, or dtype behavior.
- Change ordering-dependent logic.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = [".shape", ".shape["]




[[check]]
key = "mask-built-in-layer-loop"
name = "Mask Built In Layer Loop"
description = "Detects attention masks being rebuilt inside per-layer loops"
category = "ml-specific"
keyword = "ML_MASK_IN_LOOP"

detection_rules = """Only flag if:
- An attention mask is created inside a loop over layers/blocks
- The same mask could be created once before the loop
- Operations like torch.tril, torch.ones used for causal mask

DO NOT flag:
- Mask used once (not in loop)
- Dynamic masks that change per iteration
- Mask creation outside loops
- Loops that are not over layers/blocks
"""

fix_recipes = """A) Invariant mask creation inside layer loop:
- Move mask creation outside the layer loop
- Reuse the same mask tensor for all layers
- Ensure device/dtype match the tensors used in attention

B) If mask depends only on sequence length and is constant:
- Build once and reuse (optionally cache within the function scope)

Avoid:
- Changing mask shape semantics (broadcasting).
- Moving truly dynamic mask logic outside the loop.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = ["torch.tril(", "torch.ones("]




[[check]]
key = "growing-container"
name = "Growing Containers"
description = "Detects loops that grow containers while iterating"
category = "performance"
keyword = "GROWING_CONTAINER"

detection_rules = """DANGEROUS pattern to find:
```python
for item in my_list:      # Iterating over my_list
    my_list.append(...)   # Growing THE SAME my_list - DANGEROUS!
```

The variable name after "for item in" MUST match the variable name before ".append()".

SAFE patterns (respond with OK):
- `for x in list_a:` with `list_b.append()` - Different variables, SAFE
- `for x in items:` with `items[x] = val` - Modifying elements, not growing, SAFE
- Assigning into tensors/arrays (e.g., `tensor[i, j] = ...`) is SAFE
"""

fix_recipes = """A) If code appends to the same list it is iterating:
- Iterate over a snapshot: `for x in my_list[:]` (minimal change) OR `for x in list(my_list)`
- Or collect additions in a separate list and extend after the loop (often safest)

Preserve semantics:
- If the original intended to process newly appended items too, do NOT change behavior; instead add a comment that it is intentionally growing and no safe performance fix exists without redesign.
"""

detection_prompt = "{template:detection_basis}"
solution_prompt  = "{template:solution_basis}"
verifier_prompt  = "{template:verifier_basis}"
[check.guard]
require_any = [".append("]
